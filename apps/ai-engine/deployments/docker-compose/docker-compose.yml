services:
  # Weaviate Vector Database
  weaviate:
    image: semitechnologies/weaviate:1.27.0
    container_name: telar-weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      CLUSTER_HOSTNAME: 'node1'
    ports:
      - "8080:8080"
    volumes:
      - weaviate_data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - telar-network

  # AI Engine Service
  ai-engine:
    build:
      context: ../../
      dockerfile: Dockerfile
    container_name: telar-ai-engine
    restart: unless-stopped
    environment:
      # Server Configuration
      PORT: ${SERVER_PORT:-8000}
      HOST: "0.0.0.0"
      SERVER_HOST: ${SERVER_HOST:-localhost}
      SERVER_ENV: ${SERVER_ENV:-development}
      
      # Fully Configurable LLM Configuration
      EMBEDDING_PROVIDER: ${EMBEDDING_PROVIDER:-ollama}        # Supported: ollama, openai
      COMPLETION_PROVIDER: ${COMPLETION_PROVIDER:-ollama}      # Supported: ollama, groq, openai, openrouter 
      
      # Ollama Configuration 
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-nomic-embed-text}
      COMPLETION_MODEL: ${COMPLETION_MODEL:-llama3:8b}
      
      # Groq Configuration (Completions only - does not support embeddings)
      GROQ_API_KEY: ${GROQ_API_KEY:-}
      GROQ_MODEL: ${GROQ_MODEL:-llama-3.1-8b-instant}
      
      # OpenAI Configuration (Optional for embeddings and/or completions)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-3.5-turbo}
      
      # OpenRouter Configuration (Uses OpenAI compatibility - completions only)
      # Note: OpenRouter does not support embeddings
      # Use OPENAI_API_KEY, OPENAI_BASE_URL, and OPENAI_MODEL for OpenRouter
      
      # Vector Database Configuration
      WEAVIATE_URL: ${WEAVIATE_URL:-http://weaviate:8080}
      WEAVIATE_API_KEY: ${WEAVIATE_API_KEY:-}
      
      # Service Configuration
      LOG_LEVEL: ${LOG_LEVEL:-info}
      CORS_ENABLED: ${CORS_ENABLED:-true}
      CORS_ORIGINS: ${CORS_ORIGINS:-*}
    ports:
      - "${SERVER_PORT:-8000}:${SERVER_PORT:-8000}"
    depends_on:
      weaviate:
        condition: service_healthy
    networks:
      - telar-network
    volumes:
      - ai_engine_logs:/app/logs

volumes:
  weaviate_data:
    driver: local
  ai_engine_logs:
    driver: local

networks:
  telar-network:
    driver: bridge
